# Data Science Doctor
## Tutorial Notebooks on Data Science and Machine Learning

## Perceptron
<details>
### Overview
* The [perceptron](https://en.wikipedia.org/wiki/Perceptron) is an algorithm for supervised learning of a linear binary classifiers. 
* It dates back to the late 1950s and its first implementation, in custom hardware, was one of the first artificial neural networks to be produced. 

### You Will Learn
1. What can a perceptron learn?
2. How does a perceptron work?
3. Play with an interactive simulation to understand the effect of learning rate and number of epochs
4. What does a Perceptron can **not** learn? 
</details>

## Polynom Fit as a Linear Regression Problem + Gradient Descent
<details>
### Overview
Learn how to solve a linear regression problem (polynomial fit as an example) using a gradient descent algorithm. 
The concepts you will learn are the basics introduction to **Deep Learning**.

### You Will Learn
1. How to generate a true-underlying random model
2. How to sample data from the model with noise
3. How to define a model for the observed sampled data
4. How to fit the model to the data
5. Interactively experiment with different settings (e.g. learning rate) and learn these lessons
    a. The effect of learning rate (too small too slow, too large -> overflow)
    b. The effect of number of iteration (too little->no convergance, too many->slow and redundant)
    c. Bias-variance tradeoff: if the model is too simple or too complex it hurts dev set loss
    d. The effect of noise: more samples are needed for convergance 
    e. Learning curve: the effect of increasing the number of training data (in biased regim it is not helpful).
</details>
